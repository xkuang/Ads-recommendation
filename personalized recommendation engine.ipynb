{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d850f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c6a301e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (30000, 23)\n",
      "Test set shape: (20000, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>interaction</th>\n",
       "      <th>user_feature_0</th>\n",
       "      <th>item_feature_0</th>\n",
       "      <th>user_feature_1</th>\n",
       "      <th>item_feature_1</th>\n",
       "      <th>user_feature_2</th>\n",
       "      <th>item_feature_2</th>\n",
       "      <th>user_feature_3</th>\n",
       "      <th>...</th>\n",
       "      <th>user_feature_5</th>\n",
       "      <th>item_feature_5</th>\n",
       "      <th>user_feature_6</th>\n",
       "      <th>item_feature_6</th>\n",
       "      <th>user_feature_7</th>\n",
       "      <th>item_feature_7</th>\n",
       "      <th>user_feature_8</th>\n",
       "      <th>item_feature_8</th>\n",
       "      <th>user_feature_9</th>\n",
       "      <th>item_feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>0.373641</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.332912</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.176154</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.865701</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.032110</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.643868</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.762949</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.759487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>0.886074</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.729034</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.927810</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.006958</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.240127</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.100807</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.260211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>0.177043</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.028520</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.909304</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.152148</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.912230</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.892796</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.653901</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.672234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.984872</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.877833</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.344787</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.291517</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.562712</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.099731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.37454</td>\n",
       "      <td>0.921956</td>\n",
       "      <td>0.950714</td>\n",
       "      <td>0.140770</td>\n",
       "      <td>0.731994</td>\n",
       "      <td>0.224897</td>\n",
       "      <td>0.598658</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155995</td>\n",
       "      <td>0.619351</td>\n",
       "      <td>0.058084</td>\n",
       "      <td>0.232134</td>\n",
       "      <td>0.866176</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.601115</td>\n",
       "      <td>0.757151</td>\n",
       "      <td>0.708073</td>\n",
       "      <td>0.985207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  interaction  user_feature_0  item_feature_0  \\\n",
       "0        0        0            0         0.37454        0.373641   \n",
       "1        0        1            1         0.37454        0.886074   \n",
       "2        0        2            0         0.37454        0.177043   \n",
       "3        0        3            1         0.37454        0.005339   \n",
       "4        0        4            0         0.37454        0.921956   \n",
       "\n",
       "   user_feature_1  item_feature_1  user_feature_2  item_feature_2  \\\n",
       "0        0.950714        0.332912        0.731994        0.176154   \n",
       "1        0.950714        0.729034        0.731994        0.927810   \n",
       "2        0.950714        0.028520        0.731994        0.909304   \n",
       "3        0.950714        0.984872        0.731994        0.877833   \n",
       "4        0.950714        0.140770        0.731994        0.224897   \n",
       "\n",
       "   user_feature_3  ...  user_feature_5  item_feature_5  user_feature_6  \\\n",
       "0        0.598658  ...        0.155995        0.865701        0.058084   \n",
       "1        0.598658  ...        0.155995        0.014080        0.058084   \n",
       "2        0.598658  ...        0.155995        0.152148        0.058084   \n",
       "3        0.598658  ...        0.155995        0.344787        0.058084   \n",
       "4        0.598658  ...        0.155995        0.619351        0.058084   \n",
       "\n",
       "   item_feature_6  user_feature_7  item_feature_7  user_feature_8  \\\n",
       "0        0.032110        0.866176        0.643868        0.601115   \n",
       "1        0.006958        0.866176        0.240127        0.601115   \n",
       "2        0.912230        0.866176        0.892796        0.601115   \n",
       "3        0.893649        0.866176        0.291517        0.601115   \n",
       "4        0.232134        0.866176        0.000943        0.601115   \n",
       "\n",
       "   item_feature_8  user_feature_9  item_feature_9  \n",
       "0        0.762949        0.708073        0.759487  \n",
       "1        0.100807        0.708073        0.260211  \n",
       "2        0.653901        0.708073        0.672234  \n",
       "3        0.562712        0.708073        0.099731  \n",
       "4        0.757151        0.708073        0.985207  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate user data\n",
    "n_users = 1000\n",
    "n_items = 50\n",
    "n_features = 10\n",
    "\n",
    "# Create user features\n",
    "user_features = np.random.rand(n_users, n_features)\n",
    "\n",
    "# Create item features\n",
    "item_features = np.random.rand(n_items, n_features)\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = np.random.randint(0, 2, size=(n_users, n_items))\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'user_id': np.repeat(np.arange(n_users), n_items),\n",
    "    'item_id': np.tile(np.arange(n_items), n_users),\n",
    "    'interaction': interaction_matrix.flatten()\n",
    "})\n",
    "\n",
    "# Add some user and item features\n",
    "for i in range(n_features):\n",
    "    df[f'user_feature_{i}'] = np.repeat(user_features[:, i], n_items)\n",
    "    df[f'item_feature_{i}'] = np.tile(item_features[:, i], n_users)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.4, random_state=42)\n",
    "\n",
    "train_df['user_id'] = train_df['user_id'].astype(int)\n",
    "train_df['item_id'] = train_df['item_id'].astype(int)\n",
    "train_df['interaction'] = train_df['interaction'].astype(float)\n",
    "\n",
    "test_df['user_id'] = test_df['user_id'].astype(int)\n",
    "test_df['item_id'] = test_df['item_id'].astype(int)\n",
    "test_df['interaction'] = test_df['interaction'].astype(float)\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60517da8",
   "metadata": {},
   "source": [
    "# User-based collaborative filtering: Recommends items that similar users have liked "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9a98d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 366: [21, 37, 32, 39, 29]\n",
      "Precision@5: 0.5172\n",
      "Recall@5: 0.2651\n",
      "F1 Score: 0.3505\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "class UserBasedCollaborativeFiltering:\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.n_neighbors = n_neighbors\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.user_item_matrix = self._create_user_item_matrix(train_data)\n",
    "        self.user_similarity = cosine_similarity(self.user_item_matrix)\n",
    "        self.user_id_map = {user_id: idx for idx, user_id in enumerate(self.user_item_matrix.index)}\n",
    "        \n",
    "    def _create_user_item_matrix(self, data):\n",
    "        return data.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "    \n",
    "    def get_user_neighborhood(self, user_id):\n",
    "        if user_id not in self.user_id_map:\n",
    "            return []\n",
    "        user_idx = self.user_id_map[user_id]\n",
    "        user_similarities = self.user_similarity[user_idx]\n",
    "        similar_users = user_similarities.argsort()[::-1][1:self.n_neighbors+1]\n",
    "        return [self.user_item_matrix.index[idx] for idx in similar_users]\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        if user_id not in self.user_item_matrix.index or item_id not in self.user_item_matrix.columns:\n",
    "            return 0\n",
    "        \n",
    "        neighborhood = self.get_user_neighborhood(user_id)\n",
    "        user_mean = self.user_item_matrix.loc[user_id].mean()\n",
    "        \n",
    "        if not neighborhood:\n",
    "            return user_mean\n",
    "        \n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        user_idx = self.user_id_map[user_id]\n",
    "        for neighbor in neighborhood:\n",
    "            neighbor_idx = self.user_id_map[neighbor]\n",
    "            if self.user_item_matrix.loc[neighbor, item_id] > 0:\n",
    "                neighbor_mean = self.user_item_matrix.loc[neighbor].mean()\n",
    "                numerator += (self.user_item_matrix.loc[neighbor, item_id] - neighbor_mean) * self.user_similarity[user_idx][neighbor_idx]\n",
    "                denominator += abs(self.user_similarity[user_idx][neighbor_idx])\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return user_mean\n",
    "        \n",
    "        return user_mean + (numerator / denominator)\n",
    "    \n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        if user_id not in self.user_item_matrix.index:\n",
    "            return []\n",
    "        \n",
    "        user_items = set(self.train_data[self.train_data['user_id'] == user_id]['item_id'])\n",
    "        all_items = set(self.train_data['item_id'])\n",
    "        candidate_items = all_items - user_items\n",
    "        \n",
    "        item_scores = [(item, self.predict(user_id, item)) for item in candidate_items]\n",
    "        item_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [item for item, score in item_scores[:n_recommendations]]\n",
    "\n",
    "# Train the model\n",
    "ubcf = UserBasedCollaborativeFiltering(n_neighbors=5)\n",
    "ubcf.fit(train_df)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = train_df['user_id'].iloc[0]  # Use an existing user_id from the training set\n",
    "recommendations = ubcf.recommend(user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_recommendations(model, test_data, top_n=5):\n",
    "    user_item_interactions = defaultdict(set)\n",
    "    for _, row in test_data.iterrows():\n",
    "        if row['interaction'] > 0:\n",
    "            user_item_interactions[row['user_id']].add(row['item_id'])\n",
    "    \n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    user_count = 0\n",
    "    \n",
    "    for user in user_item_interactions:\n",
    "        if user in model.user_item_matrix.index:\n",
    "            recommended_items = set(model.recommend(user, n_recommendations=top_n))\n",
    "            relevant_items = user_item_interactions[user]\n",
    "            \n",
    "            if len(relevant_items) > 0:\n",
    "                precision = len(recommended_items.intersection(relevant_items)) / len(recommended_items)\n",
    "                recall = len(recommended_items.intersection(relevant_items)) / len(relevant_items)\n",
    "                \n",
    "                precision_sum += precision\n",
    "                recall_sum += recall\n",
    "                user_count += 1\n",
    "    \n",
    "    avg_precision = precision_sum / user_count if user_count > 0 else 0\n",
    "    avg_recall = recall_sum / user_count if user_count > 0 else 0\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, f1_score\n",
    "\n",
    "precision, recall, f1 = evaluate_recommendations(ubcf, test_df)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afea6511",
   "metadata": {},
   "source": [
    "# Item-based collaborative filtering: Recommends items similar to those the user has liked in the past"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b87520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 366: [3, 4, 7, 10, 14]\n",
      "Precision@5: 0.5018\n",
      "Recall@5: 0.2570\n",
      "F1 Score: 0.3399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "class ItemBasedCollaborativeFiltering:\n",
    "    def __init__(self, n_similar_items=5):\n",
    "        self.n_similar_items = n_similar_items\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.item_user_matrix = self._create_item_user_matrix(train_data)\n",
    "        self.item_similarity = cosine_similarity(self.item_user_matrix.T)\n",
    "        self.item_id_map = {item_id: idx for idx, item_id in enumerate(self.item_user_matrix.columns)}\n",
    "        \n",
    "    def _create_item_user_matrix(self, data):\n",
    "        return data.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "    \n",
    "    def get_similar_items(self, item_id):\n",
    "        if item_id not in self.item_id_map:\n",
    "            return []\n",
    "        item_idx = self.item_id_map[item_id]\n",
    "        item_similarities = self.item_similarity[item_idx]\n",
    "        similar_items = item_similarities.argsort()[::-1][1:self.n_similar_items+1]\n",
    "        return [self.item_user_matrix.columns[idx] for idx in similar_items]\n",
    "    \n",
    "    def predict(self, user_id, item_id):\n",
    "        if user_id not in self.item_user_matrix.index or item_id not in self.item_user_matrix.columns:\n",
    "            return 0\n",
    "        \n",
    "        similar_items = self.get_similar_items(item_id)\n",
    "        user_ratings = self.item_user_matrix.loc[user_id]\n",
    "        \n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        item_idx = self.item_id_map[item_id]\n",
    "        for similar_item in similar_items:\n",
    "            similar_item_idx = self.item_id_map[similar_item]\n",
    "            if user_ratings[similar_item] > 0:\n",
    "                numerator += user_ratings[similar_item] * self.item_similarity[item_idx][similar_item_idx]\n",
    "                denominator += abs(self.item_similarity[item_idx][similar_item_idx])\n",
    "        \n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        \n",
    "        return numerator / denominator\n",
    "    \n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        if user_id not in self.item_user_matrix.index:\n",
    "            return []\n",
    "        \n",
    "        user_items = set(self.train_data[self.train_data['user_id'] == user_id]['item_id'])\n",
    "        all_items = set(self.train_data['item_id'])\n",
    "        candidate_items = all_items - user_items\n",
    "        \n",
    "        item_scores = [(item, self.predict(user_id, item)) for item in candidate_items]\n",
    "        item_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [item for item, score in item_scores[:n_recommendations]]\n",
    "\n",
    "# Train the model\n",
    "ibcf = ItemBasedCollaborativeFiltering(n_similar_items=5)\n",
    "ibcf.fit(train_df)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = train_df['user_id'].iloc[0]  # Use an existing user_id from the training set\n",
    "recommendations = ibcf.recommend(user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_recommendations(model, test_data, top_n=5):\n",
    "    user_item_interactions = defaultdict(set)\n",
    "    for _, row in test_data.iterrows():\n",
    "        if row['interaction'] > 0:\n",
    "            user_item_interactions[row['user_id']].add(row['item_id'])\n",
    "    \n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    user_count = 0\n",
    "    \n",
    "    for user in user_item_interactions:\n",
    "        if user in model.item_user_matrix.index:\n",
    "            recommended_items = set(model.recommend(user, n_recommendations=top_n))\n",
    "            relevant_items = user_item_interactions[user]\n",
    "            \n",
    "            if len(relevant_items) > 0:\n",
    "                precision = len(recommended_items.intersection(relevant_items)) / len(recommended_items)\n",
    "                recall = len(recommended_items.intersection(relevant_items)) / len(relevant_items)\n",
    "                \n",
    "                precision_sum += precision\n",
    "                recall_sum += recall\n",
    "                user_count += 1\n",
    "    \n",
    "    avg_precision = precision_sum / user_count if user_count > 0 else 0\n",
    "    avg_recall = recall_sum / user_count if user_count > 0 else 0\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, f1_score\n",
    "\n",
    "precision, recall, f1 = evaluate_recommendations(ibcf, test_df)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb05e011",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "422976ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.33195486643992456\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "def matrix_factorization_svd(train_df, test_df, n_factors=5):\n",
    "    # Create user-item matrix\n",
    "    user_item_matrix = train_df.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "    \n",
    "    # Convert to numpy array\n",
    "    user_item_array = user_item_matrix.values\n",
    "    \n",
    "    # Perform SVD\n",
    "    U, sigma, Vt = svds(user_item_array, k=n_factors)\n",
    "    \n",
    "    # Reconstruct the matrix\n",
    "    sigma_diag = np.diag(sigma)\n",
    "    predicted_ratings = np.dot(np.dot(U, sigma_diag), Vt)\n",
    "    \n",
    "    # Create a DataFrame with the predicted ratings\n",
    "    predicted_df = pd.DataFrame(predicted_ratings, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    test_interactions = test_df[['user_id', 'item_id', 'interaction']]\n",
    "    test_predictions = test_interactions.apply(lambda row: predicted_df.loc[row['user_id'], row['item_id']] if row['user_id'] in predicted_df.index and row['item_id'] in predicted_df.columns else 0, axis=1)\n",
    "    \n",
    "    mse = np.mean((test_interactions['interaction'] - test_predictions) ** 2)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    \n",
    "    return predicted_df\n",
    "\n",
    "mf_predictions = matrix_factorization_svd(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b23940",
   "metadata": {},
   "source": [
    "# Probabilistic Matrix Factorization (PMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd565bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Train MSE = 0.4994, Test MSE = 0.5067\n",
      "Iteration 10: Train MSE = 0.4142, Test MSE = 0.4293\n",
      "Iteration 20: Train MSE = 0.2391, Test MSE = 0.2625\n",
      "Iteration 30: Train MSE = 0.2341, Test MSE = 0.2618\n",
      "Iteration 40: Train MSE = 0.2280, Test MSE = 0.2624\n",
      "Iteration 50: Train MSE = 0.2195, Test MSE = 0.2640\n",
      "Iteration 60: Train MSE = 0.2090, Test MSE = 0.2666\n",
      "Iteration 70: Train MSE = 0.1984, Test MSE = 0.2704\n",
      "Iteration 80: Train MSE = 0.1892, Test MSE = 0.2750\n",
      "Iteration 90: Train MSE = 0.1819, Test MSE = 0.2798\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 0: [ 1 48 35 32 46]\n",
      "Final Train MSE: 0.1771\n",
      "Final Test MSE: 0.2838\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import expit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ProbabilisticMatrixFactorization:\n",
    "    def __init__(self, n_factors=10, n_iterations=100, learning_rate=0.005, regularization=0.02):\n",
    "        self.n_factors = n_factors\n",
    "        self.n_iterations = n_iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "    \n",
    "    def fit(self, train_data, test_data):\n",
    "        self.n_users = train_data['user_id'].nunique()\n",
    "        self.n_items = train_data['item_id'].nunique()\n",
    "        \n",
    "        # Initialize latent factors\n",
    "        self.user_factors = np.random.normal(scale=1./self.n_factors, size=(self.n_users, self.n_factors))\n",
    "        self.item_factors = np.random.normal(scale=1./self.n_factors, size=(self.n_items, self.n_factors))\n",
    "        \n",
    "        # Training loop\n",
    "        train_errors = []\n",
    "        test_errors = []\n",
    "        for iteration in range(self.n_iterations):\n",
    "            self._update_factors(train_data)\n",
    "            train_mse = self._compute_mse(train_data)\n",
    "            test_mse = self._compute_mse(test_data)\n",
    "            train_errors.append(train_mse)\n",
    "            test_errors.append(test_mse)\n",
    "            if iteration % 10 == 0:\n",
    "                print(f\"Iteration {iteration}: Train MSE = {train_mse:.4f}, Test MSE = {test_mse:.4f}\")\n",
    "        \n",
    "        # Plot training and test errors\n",
    "        plt.plot(range(self.n_iterations), train_errors, label='Train MSE')\n",
    "        plt.plot(range(self.n_iterations), test_errors, label='Test MSE')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Mean Squared Error')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def _update_factors(self, data):\n",
    "        for _, row in data.iterrows():\n",
    "            u, i, r = int(row['user_id']), int(row['item_id']), row['interaction']\n",
    "            prediction = self._predict(u, i)\n",
    "            error = r - prediction\n",
    "            \n",
    "            # Update user factors\n",
    "            user_factor_gradient = error * self.item_factors[i] - self.regularization * self.user_factors[u]\n",
    "            self.user_factors[u] += self.learning_rate * user_factor_gradient\n",
    "            \n",
    "            # Update item factors\n",
    "            item_factor_gradient = error * self.user_factors[u] - self.regularization * self.item_factors[i]\n",
    "            self.item_factors[i] += self.learning_rate * item_factor_gradient\n",
    "    \n",
    "    def _predict(self, user, item):\n",
    "        return np.dot(self.user_factors[user], self.item_factors[item])\n",
    "    \n",
    "    def _compute_mse(self, data):\n",
    "        predictions = np.array([self._predict(int(row['user_id']), int(row['item_id'])) for _, row in data.iterrows()])\n",
    "        actual = data['interaction'].values\n",
    "        return np.mean((predictions - actual) ** 2)\n",
    "    \n",
    "    def recommend(self, user, n_recommendations=5):\n",
    "        user_vector = self.user_factors[user]\n",
    "        scores = np.dot(self.item_factors, user_vector)\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return top_items\n",
    "\n",
    "# Train the model\n",
    "pmf = ProbabilisticMatrixFactorization(n_factors=10, n_iterations=100, learning_rate=0.005, regularization=0.02)\n",
    "pmf.fit(train_df, test_df)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = 0\n",
    "recommendations = pmf.recommend(user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "train_mse = pmf._compute_mse(train_df)\n",
    "test_mse = pmf._compute_mse(test_df)\n",
    "print(f\"Final Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Final Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f7e9c",
   "metadata": {},
   "source": [
    "# Non-negative Matrix Factorization (NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8e7bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 20: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 30: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 40: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 50: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 60: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 70: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 80: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 90: Train MSE = 0.1835, Test MSE = 0.2102\n",
      "Iteration 100: Train MSE = 0.1835, Test MSE = 0.2102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1759: ConvergenceWarning: Maximum number of iterations 100 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 0: [10 18 48 40 32]\n",
      "Final Train MSE: 0.1835\n",
      "Final Test MSE: 0.2102\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class NonNegativeMatrixFactorization:\n",
    "    def __init__(self, n_factors=10, n_iterations=100):\n",
    "        self.n_factors = n_factors\n",
    "        self.n_iterations = n_iterations\n",
    "    \n",
    "    def fit(self, train_data, test_data):\n",
    "        self.n_users = train_data['user_id'].max() + 1\n",
    "        self.n_items = train_data['item_id'].max() + 1\n",
    "        \n",
    "        # Create user-item matrices\n",
    "        self.train_matrix = self._create_matrix(train_data)\n",
    "        self.test_matrix = self._create_matrix(test_data)\n",
    "        \n",
    "        # Initialize NMF model\n",
    "        self.model = NMF(n_components=self.n_factors, init='random', random_state=42, max_iter=self.n_iterations)\n",
    "        \n",
    "        # Fit the model\n",
    "        self.user_factors = self.model.fit_transform(self.train_matrix)\n",
    "        self.item_factors = self.model.components_\n",
    "        \n",
    "        # Compute and plot errors\n",
    "        train_errors = []\n",
    "        test_errors = []\n",
    "        for i in range(self.n_iterations):\n",
    "            train_pred = np.dot(self.user_factors[:, :i+1], self.item_factors[:i+1, :])\n",
    "            test_pred = np.dot(self.user_factors[:, :i+1], self.item_factors[:i+1, :])\n",
    "            \n",
    "            train_mse = mean_squared_error(self.train_matrix, train_pred)\n",
    "            test_mse = mean_squared_error(self.test_matrix, test_pred)\n",
    "            \n",
    "            train_errors.append(train_mse)\n",
    "            test_errors.append(test_mse)\n",
    "            \n",
    "            if (i+1) % 10 == 0:\n",
    "                print(f\"Iteration {i+1}: Train MSE = {train_mse:.4f}, Test MSE = {test_mse:.4f}\")\n",
    "        \n",
    "        # Plot training and test errors\n",
    "        plt.plot(range(1, self.n_iterations+1), train_errors, label='Train MSE')\n",
    "        plt.plot(range(1, self.n_iterations+1), test_errors, label='Test MSE')\n",
    "        plt.xlabel('Iteration')\n",
    "        plt.ylabel('Mean Squared Error')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def _create_matrix(self, data):\n",
    "        return data.pivot(index='user_id', columns='item_id', values='interaction').fillna(0).values\n",
    "    \n",
    "    def predict(self, user, item):\n",
    "        return np.dot(self.user_factors[user], self.item_factors[:, item])\n",
    "    \n",
    "    def recommend(self, user, n_recommendations=5):\n",
    "        user_vector = self.user_factors[user]\n",
    "        scores = np.dot(user_vector, self.item_factors)\n",
    "        top_items = np.argsort(scores)[::-1][:n_recommendations]\n",
    "        return top_items\n",
    "\n",
    "# Train the model\n",
    "nmf = NonNegativeMatrixFactorization(n_factors=5, n_iterations=100)\n",
    "nmf.fit(train_df, test_df)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = 0\n",
    "recommendations = nmf.recommend(user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "train_pred = np.dot(nmf.user_factors, nmf.item_factors)\n",
    "test_pred = np.dot(nmf.user_factors, nmf.item_factors)\n",
    "\n",
    "train_mse = mean_squared_error(nmf.train_matrix, train_pred)\n",
    "test_mse = mean_squared_error(nmf.test_matrix, test_pred)\n",
    "\n",
    "print(f\"Final Train MSE: {train_mse:.4f}\")\n",
    "print(f\"Final Test MSE: {test_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa72578e",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cebad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.10/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def bpr_model(train_df, test_df):\n",
    "    # Create interaction matrices\n",
    "    train_matrix = train_df.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "    test_matrix = test_df.pivot(index='user_id', columns='item_id', values='interaction').fillna(0)\n",
    "    \n",
    "    # Convert to sparse matrices\n",
    "    train_sparse = csr_matrix(train_matrix.values)\n",
    "    test_sparse = csr_matrix(test_matrix.values)\n",
    "    \n",
    "    # Get the number of users and items\n",
    "    n_users, n_items = train_sparse.shape\n",
    "    \n",
    "    # Initialize and train the model\n",
    "    model = LightFM(learning_rate=0.05, loss='bpr')\n",
    "    model.fit(train_sparse, epochs=10)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    train_precision = precision_at_k(model, train_sparse, k=10).mean()\n",
    "    test_precision = precision_at_k(model, test_sparse, k=10).mean()\n",
    "    \n",
    "    print(f\"Train Precision@10: {train_precision}\")\n",
    "    print(f\"Test Precision@10: {test_precision}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "#bpr_model = bpr_model(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3ea233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Precision@10: 0.5993000268936157\n",
      "Test Precision@10: 0.11990001052618027\n"
     ]
    }
   ],
   "source": [
    "def remap_ids(df, user_col='user_id', item_col='item_id'):\n",
    "    user_id_map = {id: i for i, id in enumerate(df[user_col].unique())}\n",
    "    item_id_map = {id: i for i, id in enumerate(df[item_col].unique())}\n",
    "    \n",
    "    df_remapped = df.copy()\n",
    "    df_remapped[user_col] = df_remapped[user_col].map(user_id_map)\n",
    "    df_remapped[item_col] = df_remapped[item_col].map(item_id_map)\n",
    "    \n",
    "    return df_remapped, user_id_map, item_id_map\n",
    "\n",
    "train_df_remapped, user_map, item_map = remap_ids(train_df)\n",
    "test_df_remapped = test_df.copy()\n",
    "test_df_remapped['user_id'] = test_df_remapped['user_id'].map(user_map)\n",
    "test_df_remapped['item_id'] = test_df_remapped['item_id'].map(item_map)\n",
    "\n",
    "# Now use train_df_remapped and test_df_remapped in your bpr_model function\n",
    "bpr_model = bpr_model(train_df_remapped, test_df_remapped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fed99d",
   "metadata": {},
   "source": [
    "# Random Walk with Restart (RWR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e11a61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 366: [10, 49, 31, 7, 37]\n",
      "Precision@5: 0.5090\n",
      "Recall@5: 0.2606\n",
      "F1 Score: 0.3447\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "class RandomWalkWithRestart:\n",
    "    def __init__(self, alpha=0.15, n_iterations=100):\n",
    "        self.alpha = alpha  # Probability of restarting the random walk\n",
    "        self.n_iterations = n_iterations\n",
    "    \n",
    "    def fit(self, train_data):\n",
    "        self.train_data = train_data\n",
    "        self.graph = self._create_bipartite_graph(train_data)\n",
    "        self.transition_matrix = self._create_transition_matrix()\n",
    "    \n",
    "    def _create_bipartite_graph(self, data):\n",
    "        G = nx.Graph()\n",
    "        for _, row in data.iterrows():\n",
    "            G.add_edge(f\"user_{int(row['user_id'])}\", f\"item_{int(row['item_id'])}\")\n",
    "        return G\n",
    "    \n",
    "    def _create_transition_matrix(self):\n",
    "        nodes = list(self.graph.nodes())\n",
    "        n = len(nodes)\n",
    "        transition_matrix = np.zeros((n, n))\n",
    "        \n",
    "        for i, node in enumerate(nodes):\n",
    "            neighbors = list(self.graph.neighbors(node))\n",
    "            for neighbor in neighbors:\n",
    "                j = nodes.index(neighbor)\n",
    "                transition_matrix[i, j] = 1 / len(neighbors)\n",
    "        \n",
    "        return transition_matrix\n",
    "    \n",
    "    def random_walk(self, start_node):\n",
    "        nodes = list(self.graph.nodes())\n",
    "        n = len(nodes)\n",
    "        start_index = nodes.index(start_node)\n",
    "        \n",
    "        p = np.zeros(n)\n",
    "        p[start_index] = 1\n",
    "        \n",
    "        for _ in range(self.n_iterations):\n",
    "            p = (1 - self.alpha) * np.dot(p, self.transition_matrix) + self.alpha * (np.arange(n) == start_index)\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        start_node = f\"user_{int(user_id)}\"\n",
    "        if start_node not in self.graph:\n",
    "            return []\n",
    "        \n",
    "        p = self.random_walk(start_node)\n",
    "        nodes = list(self.graph.nodes())\n",
    "        \n",
    "        item_scores = [(node, score) for node, score in zip(nodes, p) if node.startswith(\"item_\")]\n",
    "        item_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        recommended_items = [int(item.split(\"_\")[1]) for item, _ in item_scores \n",
    "                             if start_node not in self.graph.neighbors(item)]\n",
    "        \n",
    "        return recommended_items[:n_recommendations]\n",
    "\n",
    "# Train the model\n",
    "rwr = RandomWalkWithRestart(alpha=0.15, n_iterations=100)\n",
    "rwr.fit(train_df)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = train_df['user_id'].iloc[0]  # Use an existing user_id from the training set\n",
    "recommendations = rwr.recommend(user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_recommendations(model, test_data, top_n=5):\n",
    "    user_item_interactions = defaultdict(set)\n",
    "    for _, row in test_data.iterrows():\n",
    "        if row['interaction'] > 0:\n",
    "            user_item_interactions[int(row['user_id'])].add(int(row['item_id']))\n",
    "    \n",
    "    precision_sum = 0\n",
    "    recall_sum = 0\n",
    "    user_count = 0\n",
    "    \n",
    "    for user in user_item_interactions:\n",
    "        if f\"user_{user}\" in model.graph:\n",
    "            recommended_items = set(model.recommend(user, n_recommendations=top_n))\n",
    "            relevant_items = user_item_interactions[user]\n",
    "            \n",
    "            if len(relevant_items) > 0:\n",
    "                precision = len(recommended_items.intersection(relevant_items)) / len(recommended_items)\n",
    "                recall = len(recommended_items.intersection(relevant_items)) / len(relevant_items)\n",
    "                \n",
    "                precision_sum += precision\n",
    "                recall_sum += recall\n",
    "                user_count += 1\n",
    "    \n",
    "    avg_precision = precision_sum / user_count if user_count > 0 else 0\n",
    "    avg_recall = recall_sum / user_count if user_count > 0 else 0\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, f1_score\n",
    "\n",
    "precision, recall, f1 = evaluate_recommendations(rwr, test_df)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f714cb",
   "metadata": {},
   "source": [
    "# Node2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "343724d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0248814cd59544c2b8ed6bc25b1fb24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/1050 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating walks (CPU: 1): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:07<00:00,  3.52it/s]\n",
      "Generating walks (CPU: 2): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:07<00:00,  3.56it/s]\n",
      "Generating walks (CPU: 3): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:07<00:00,  3.56it/s]\n",
      "Generating walks (CPU: 4): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25/25 [00:06<00:00,  3.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 recommendations for user 366:\n",
      "User 366 not found in the model. Providing random recommendations.\n",
      "['item_43.0', 'item_1.0', 'item_6.0', 'item_11.0', 'item_2.0']\n",
      "Unique user IDs in the dataset: 1000\n",
      "Min user ID: 0\n",
      "Max user ID: 999\n",
      "First few user IDs: [366, 990, 894, 936, 550]\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from node2vec import Node2Vec\n",
    "import random\n",
    "\n",
    "def node2vec_model(train_df):\n",
    "    # Create a graph from the interaction data\n",
    "    G = nx.Graph()\n",
    "    for _, row in train_df.iterrows():\n",
    "        G.add_edge(f\"user_{row['user_id']}\", f\"item_{row['item_id']}\")\n",
    "    \n",
    "    # Generate node embeddings\n",
    "    node2vec = Node2Vec(G, dimensions=32, walk_length=20, num_walks=100, workers=4)\n",
    "    model = node2vec.fit(window=10, min_count=1)\n",
    "    \n",
    "    # Get all item nodes\n",
    "    all_items = [node for node in G.nodes() if node.startswith('item_')]\n",
    "    \n",
    "    # Function to get recommendations for a user\n",
    "    def get_recommendations(user_id, top_n=5):\n",
    "        user_node = f\"user_{user_id}\"\n",
    "        try:\n",
    "            if user_node not in model.wv.key_to_index:\n",
    "                print(f\"User {user_id} not found in the model. Providing random recommendations.\")\n",
    "                return random.sample(all_items, min(top_n, len(all_items)))\n",
    "            \n",
    "            similar_nodes = model.wv.most_similar(user_node, topn=top_n*2)  # Get more recommendations to filter\n",
    "            recommendations = [int(node[0].split('_')[1]) for node in similar_nodes if node[0].startswith('item_')][:top_n]\n",
    "            \n",
    "            # If we don't have enough recommendations, add random items\n",
    "            if len(recommendations) < top_n:\n",
    "                remaining = top_n - len(recommendations)\n",
    "                random_items = random.sample([item for item in all_items if int(item.split('_')[1]) not in recommendations], remaining)\n",
    "                recommendations.extend([int(item.split('_')[1]) for item in random_items])\n",
    "            \n",
    "            return recommendations\n",
    "        except KeyError:\n",
    "            print(f\"Error occurred while getting recommendations for user {user_id}. Providing random recommendations.\")\n",
    "            return [int(item.split('_')[1]) for item in random.sample(all_items, min(top_n, len(all_items)))]\n",
    "    \n",
    "    # Example recommendation\n",
    "    example_user = train_df['user_id'].iloc[0]\n",
    "    print(f\"Top 5 recommendations for user {example_user}:\")\n",
    "    print(get_recommendations(example_user))\n",
    "    \n",
    "    return model, get_recommendations\n",
    "\n",
    "node2vec_model, get_recommendations = node2vec_model(train_df)\n",
    "\n",
    "print(\"Unique user IDs in the dataset:\", train_df['user_id'].nunique())\n",
    "print(\"Min user ID:\", train_df['user_id'].min())\n",
    "print(\"Max user ID:\", train_df['user_id'].max())\n",
    "print(\"First few user IDs:\", train_df['user_id'].head().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d42c27",
   "metadata": {},
   "source": [
    "# Graph Convolutional Networks (GCNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c77713ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/200, Loss: 0.3383\n",
      "Epoch 20/200, Loss: 0.0248\n",
      "Epoch 30/200, Loss: 0.0004\n",
      "Epoch 40/200, Loss: 0.0000\n",
      "Epoch 50/200, Loss: 0.0000\n",
      "Epoch 60/200, Loss: 0.0000\n",
      "Epoch 70/200, Loss: 0.0000\n",
      "Epoch 80/200, Loss: 0.0000\n",
      "Epoch 90/200, Loss: 0.0000\n",
      "Epoch 100/200, Loss: 0.0000\n",
      "Epoch 110/200, Loss: 0.0000\n",
      "Epoch 120/200, Loss: 0.0000\n",
      "Epoch 130/200, Loss: 0.0000\n",
      "Epoch 140/200, Loss: 0.0000\n",
      "Epoch 150/200, Loss: 0.0000\n",
      "Epoch 160/200, Loss: 0.0000\n",
      "Epoch 170/200, Loss: 0.0000\n",
      "Epoch 180/200, Loss: 0.0000\n",
      "Epoch 190/200, Loss: 0.0000\n",
      "Epoch 200/200, Loss: 0.0000\n",
      "Top 5 recommendations for user 0: [30 26 29 15  0]\n",
      "Precision@5: 0.2174\n",
      "Recall@5: 0.1079\n",
      "F1 Score: 0.1414\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "\n",
    "class GCNRecommender(torch.nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes):\n",
    "        super(GCNRecommender, self).__init__()\n",
    "        self.conv1 = GCNConv(num_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GCNConv(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        return x\n",
    "\n",
    "def create_graph_data(df, num_users, num_items):\n",
    "    # Create edge index\n",
    "    edge_index = torch.tensor([\n",
    "        np.concatenate([df['user_id'].values, df['item_id'].values + num_users]),\n",
    "        np.concatenate([df['item_id'].values + num_users, df['user_id'].values])\n",
    "    ], dtype=torch.long)\n",
    "\n",
    "    # Create node features\n",
    "    user_features = torch.tensor(df[[f'user_feature_{i}' for i in range(10)]].values[:num_users], dtype=torch.float)\n",
    "    item_features = torch.tensor(df[[f'item_feature_{i}' for i in range(10)]].values[:num_items], dtype=torch.float)\n",
    "    x = torch.cat([user_features, item_features], dim=0)\n",
    "\n",
    "    # Create target\n",
    "    target = torch.zeros((num_users + num_items, 1), dtype=torch.float)\n",
    "    target[:num_users] = 1.0  # Set user nodes to 1\n",
    "\n",
    "    # Create graph data object\n",
    "    data = Data(x=x, edge_index=edge_index, y=target)\n",
    "    return data\n",
    "\n",
    "def train_gcn(model, data, optimizer, num_epochs=200):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index)\n",
    "        loss = F.binary_cross_entropy_with_logits(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item():.4f}')\n",
    "\n",
    "def recommend(model, data, user_id, n_recommendations=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data.x, data.edge_index)\n",
    "    user_embedding = out[user_id]\n",
    "    item_embeddings = out[n_users:]\n",
    "    scores = torch.matmul(user_embedding, item_embeddings.t())\n",
    "    _, top_items = torch.topk(scores, k=n_recommendations)\n",
    "    return top_items.numpy()\n",
    "\n",
    "# Prepare data\n",
    "n_users = 1000\n",
    "n_items = 50\n",
    "data = create_graph_data(train_df, n_users, n_items)\n",
    "\n",
    "# Initialize and train the model\n",
    "model = GCNRecommender(num_features=10, hidden_channels=64, num_classes=1)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "train_gcn(model, data, optimizer)\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = 0\n",
    "recommendations = recommend(model, data, user_id)\n",
    "print(f\"Top 5 recommendations for user {user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate_recommendations(model, data, test_df, n_users, n_items, top_n=5):\n",
    "    true_interactions = defaultdict(set)\n",
    "    for _, row in test_df.iterrows():\n",
    "        if row['interaction'] > 0:\n",
    "            true_interactions[row['user_id']].add(row['item_id'])\n",
    "    \n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for user_id in range(n_users):\n",
    "        if user_id in true_interactions:\n",
    "            recommended_items = set(recommend(model, data, user_id, n_recommendations=top_n))\n",
    "            relevant_items = true_interactions[user_id]\n",
    "            \n",
    "            precision = len(recommended_items.intersection(relevant_items)) / len(recommended_items)\n",
    "            recall = len(recommended_items.intersection(relevant_items)) / len(relevant_items)\n",
    "            \n",
    "            precision_list.append(precision)\n",
    "            recall_list.append(recall)\n",
    "            \n",
    "            if precision + recall > 0:\n",
    "                f1 = 2 * (precision * recall) / (precision + recall)\n",
    "            else:\n",
    "                f1 = 0\n",
    "            f1_list.append(f1)\n",
    "    \n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "precision, recall, f1 = evaluate_recommendations(model, data, test_df, n_users, n_items)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e19b399",
   "metadata": {},
   "source": [
    "# Neural Collaborative Filtering (NCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3a583e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4990 - loss: 0.6936 - val_accuracy: 0.5041 - val_loss: 0.6937\n",
      "Epoch 2/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5636 - loss: 0.6852 - val_accuracy: 0.5062 - val_loss: 0.6979\n",
      "Epoch 3/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5999 - loss: 0.6689 - val_accuracy: 0.5038 - val_loss: 0.7064\n",
      "Epoch 4/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6506 - loss: 0.6382 - val_accuracy: 0.5084 - val_loss: 0.7291\n",
      "Epoch 5/5\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.6895 - loss: 0.5963 - val_accuracy: 0.5034 - val_loss: 0.7552\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 247us/step - accuracy: 0.5082 - loss: 0.7528\n",
      "Test Loss: 0.7551916241645813\n",
      "Test Accuracy: 0.5034499764442444\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def ncf_model(train_df, test_df, embedding_size=100, n_hidden=50):\n",
    "    n_users = train_df['user_id'].nunique()\n",
    "    n_items = train_df['item_id'].nunique()\n",
    "    \n",
    "    # Define model architecture\n",
    "    user_input = Input(shape=(1,), name='user_input')\n",
    "    item_input = Input(shape=(1,), name='item_input')\n",
    "    \n",
    "    user_embedding = Embedding(n_users, embedding_size, name='user_embedding')(user_input)\n",
    "    item_embedding = Embedding(n_items, embedding_size, name='item_embedding')(item_input)\n",
    "    \n",
    "    user_vec = Flatten()(user_embedding)\n",
    "    item_vec = Flatten()(item_embedding)\n",
    "    \n",
    "    concat = Concatenate()([user_vec, item_vec])\n",
    "    hidden = Dense(n_hidden, activation='relu')(concat)\n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    \n",
    "    model = Model(inputs=[user_input, item_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train = [train_df['user_id'], train_df['item_id']]\n",
    "    y_train = train_df['interaction']\n",
    "    X_test = [test_df['user_id'], test_df['item_id']]\n",
    "    y_test = test_df['interaction']\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=64)\n",
    "    \n",
    "    # Evaluate model\n",
    "    loss, accuracy = model.evaluate(X_test, y_test)\n",
    "    print(f\"Test Loss: {loss}\")\n",
    "    print(f\"Test Accuracy: {accuracy}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "ncf_model = ncf_model(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508bedbc",
   "metadata": {},
   "source": [
    "# Wide & Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "204b513f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5092 - loss: 41.7282 - val_accuracy: 0.4951 - val_loss: 19.2027 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5037 - loss: 11.2510 - val_accuracy: 0.4967 - val_loss: 4.4700 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 954us/step - accuracy: 0.4943 - loss: 2.5000 - val_accuracy: 0.5038 - val_loss: 1.3548 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 984us/step - accuracy: 0.4937 - loss: 1.3044 - val_accuracy: 0.4972 - val_loss: 1.2190 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.4969 - loss: 1.1910 - val_accuracy: 0.5009 - val_loss: 1.1177 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 970us/step - accuracy: 0.5007 - loss: 1.1076 - val_accuracy: 0.4947 - val_loss: 1.0550 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 995us/step - accuracy: 0.4984 - loss: 1.0353 - val_accuracy: 0.4930 - val_loss: 1.0188 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 979us/step - accuracy: 0.4990 - loss: 0.9771 - val_accuracy: 0.4962 - val_loss: 0.9293 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 997us/step - accuracy: 0.5107 - loss: 0.9207 - val_accuracy: 0.5003 - val_loss: 0.8808 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 953us/step - accuracy: 0.5049 - loss: 0.8810 - val_accuracy: 0.4925 - val_loss: 0.8588 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 949us/step - accuracy: 0.5039 - loss: 0.8410 - val_accuracy: 0.4933 - val_loss: 0.8218 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 951us/step - accuracy: 0.5044 - loss: 0.8092 - val_accuracy: 0.5028 - val_loss: 0.7797 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 958us/step - accuracy: 0.4961 - loss: 0.7806 - val_accuracy: 0.4996 - val_loss: 0.7554 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 976us/step - accuracy: 0.5007 - loss: 0.7625 - val_accuracy: 0.4933 - val_loss: 0.7398 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 961us/step - accuracy: 0.4944 - loss: 0.7410 - val_accuracy: 0.4940 - val_loss: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 956us/step - accuracy: 0.5013 - loss: 0.7302 - val_accuracy: 0.5001 - val_loss: 0.7131 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.4991 - loss: 0.7179 - val_accuracy: 0.5038 - val_loss: 0.7052 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.5011 - loss: 0.7140 - val_accuracy: 0.4933 - val_loss: 0.7094 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 932us/step - accuracy: 0.5010 - loss: 0.7068 - val_accuracy: 0.4927 - val_loss: 0.7161 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - accuracy: 0.5043 - loss: 0.7028 - val_accuracy: 0.4979 - val_loss: 0.6965 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 900us/step - accuracy: 0.5003 - loss: 0.7028 - val_accuracy: 0.5037 - val_loss: 0.6951 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.5038 - loss: 0.6992 - val_accuracy: 0.5062 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step - accuracy: 0.5018 - loss: 0.7003 - val_accuracy: 0.5032 - val_loss: 0.7022 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 908us/step - accuracy: 0.5008 - loss: 0.6995 - val_accuracy: 0.5055 - val_loss: 0.7072 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.5023 - loss: 0.7038 - val_accuracy: 0.5023 - val_loss: 0.6948 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.5032 - loss: 0.6980 - val_accuracy: 0.4947 - val_loss: 0.6979 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 882us/step - accuracy: 0.5054 - loss: 0.6996 - val_accuracy: 0.4961 - val_loss: 0.6946 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.5076 - loss: 0.7020 - val_accuracy: 0.5034 - val_loss: 0.7038 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 919us/step - accuracy: 0.5030 - loss: 0.7016 - val_accuracy: 0.5012 - val_loss: 0.6968 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 910us/step - accuracy: 0.4985 - loss: 0.7017 - val_accuracy: 0.5049 - val_loss: 0.7099 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 869us/step - accuracy: 0.5066 - loss: 0.6993 - val_accuracy: 0.5055 - val_loss: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step - accuracy: 0.5001 - loss: 0.7023 - val_accuracy: 0.5058 - val_loss: 0.6982 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 860us/step - accuracy: 0.5047 - loss: 0.6977 - val_accuracy: 0.5026 - val_loss: 0.6976 - learning_rate: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 865us/step - accuracy: 0.4968 - loss: 0.6978 - val_accuracy: 0.4945 - val_loss: 0.7064 - learning_rate: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 885us/step - accuracy: 0.4986 - loss: 0.6989 - val_accuracy: 0.5055 - val_loss: 0.6991 - learning_rate: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 891us/step - accuracy: 0.5048 - loss: 0.6969 - val_accuracy: 0.5020 - val_loss: 0.6948 - learning_rate: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 877us/step - accuracy: 0.5064 - loss: 0.6975 - val_accuracy: 0.4941 - val_loss: 0.7015 - learning_rate: 5.0000e-04\n",
      "\u001b[1m313/313\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.4953 - loss: 0.6948\n",
      "Test Loss: 0.6946198344230652\n",
      "Test Accuracy: 0.49605000019073486\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, regularizers\n",
    "from collections import defaultdict\n",
    "\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('interaction')\n",
    "    ds = tf.data.Dataset.from_tensor_slices(({name: dataframe[name].values for name in dataframe.columns}, labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds\n",
    "\n",
    "feature_names = ['user_id', 'item_id'] + [f'user_feature_{i}' for i in range(10)] + [f'item_feature_{i}' for i in range(10)]\n",
    "\n",
    "def wide_and_deep_model(feature_names, hidden_units=[128, 64, 32]):\n",
    "    inputs = {name: layers.Input(name=name, shape=(1,)) for name in feature_names}\n",
    "    concat_inputs = layers.Concatenate()(list(inputs.values()))\n",
    "    \n",
    "    # Wide part\n",
    "    wide = layers.Dense(1, kernel_regularizer=regularizers.l2(0.01))(concat_inputs)\n",
    "    \n",
    "    # Deep part\n",
    "    deep = layers.Dense(hidden_units[0], activation='relu', kernel_regularizer=regularizers.l2(0.01))(concat_inputs)\n",
    "    deep = layers.Dropout(0.3)(deep)\n",
    "    for units in hidden_units[1:]:\n",
    "        deep = layers.Dense(units, activation='relu', kernel_regularizer=regularizers.l2(0.01))(deep)\n",
    "        deep = layers.Dropout(0.3)(deep)\n",
    "    deep = layers.Dense(1, kernel_regularizer=regularizers.l2(0.01))(deep)\n",
    "    \n",
    "    combined = layers.Add()([wide, deep])\n",
    "    output = layers.Activation('sigmoid')(combined)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=output)\n",
    "    return model\n",
    "\n",
    "# Prepare the data\n",
    "batch_size = 64  # Increased batch size\n",
    "train_ds = df_to_dataset(train_df, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test_df, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "# Create and compile the model\n",
    "model = wide_and_deep_model(feature_names)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Implement early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds, \n",
    "    epochs=100,  # Increased number of epochs\n",
    "    validation_data=test_ds,\n",
    "    callbacks=[early_stopping, lr_scheduler]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b831c1d",
   "metadata": {},
   "source": [
    "# DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "405c2aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (3500, 23)\n",
      "Test set shape: (1500, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ user_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_2       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ user_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ item_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> â”‚ concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ flatten_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_3       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span> â”‚ concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚        \u001b[38;5;34m800\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_1         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚        \u001b[38;5;34m400\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ user_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_2       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ user_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ item_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m2,368\u001b[0m â”‚ concatenate_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ flatten_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)        â”‚        \u001b[38;5;34m528\u001b[0m â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_3       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m25\u001b[0m â”‚ concatenate_3[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,201</span> (24.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,201\u001b[0m (24.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,201</span> (24.22 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,201\u001b[0m (24.22 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4876 - loss: 0.6947 - val_accuracy: 0.5214 - val_loss: 0.6935\n",
      "Epoch 2/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 523us/step - accuracy: 0.5495 - loss: 0.6885 - val_accuracy: 0.4800 - val_loss: 0.6953\n",
      "Epoch 3/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 527us/step - accuracy: 0.5364 - loss: 0.6882 - val_accuracy: 0.4857 - val_loss: 0.6961\n",
      "Epoch 4/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 528us/step - accuracy: 0.5688 - loss: 0.6807 - val_accuracy: 0.4829 - val_loss: 0.7007\n",
      "Epoch 5/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 526us/step - accuracy: 0.5776 - loss: 0.6767 - val_accuracy: 0.4800 - val_loss: 0.7039\n",
      "Epoch 6/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 515us/step - accuracy: 0.5805 - loss: 0.6745 - val_accuracy: 0.4786 - val_loss: 0.7075\n",
      "Epoch 7/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 559us/step - accuracy: 0.5892 - loss: 0.6662 - val_accuracy: 0.4686 - val_loss: 0.7142\n",
      "Epoch 8/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.6028 - loss: 0.6632 - val_accuracy: 0.5071 - val_loss: 0.7221\n",
      "Epoch 9/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 548us/step - accuracy: 0.6071 - loss: 0.6612 - val_accuracy: 0.4714 - val_loss: 0.7253\n",
      "Epoch 10/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.5932 - loss: 0.6589 - val_accuracy: 0.4700 - val_loss: 0.7289\n",
      "\u001b[1m47/47\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 280us/step - accuracy: 0.4855 - loss: 0.7245\n",
      "Test Loss: 0.7244428992271423, Test Accuracy: 0.49133333563804626\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, concatenate, Add\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate user data\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "n_features = 10\n",
    "\n",
    "# Create user features\n",
    "user_features = np.random.rand(n_users, n_features)\n",
    "\n",
    "# Create item features\n",
    "item_features = np.random.rand(n_items, n_features)\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = np.random.randint(0, 2, size=(n_users, n_items))\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'user_id': np.repeat(np.arange(n_users), n_items),\n",
    "    'item_id': np.tile(np.arange(n_items), n_users),\n",
    "    'interaction': interaction_matrix.flatten()\n",
    "})\n",
    "\n",
    "# Add some user and item features\n",
    "for i in range(n_features):\n",
    "    df[f'userfeature{i}'] = np.repeat(user_features[:, i], n_items)\n",
    "    df[f'itemfeature{i}'] = np.tile(item_features[:, i], n_users)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Ensure correct data types\n",
    "train_df['user_id'] = train_df['user_id'].astype(int)\n",
    "train_df['item_id'] = train_df['item_id'].astype(int)\n",
    "train_df['interaction'] = train_df['interaction'].astype(float)\n",
    "test_df['user_id'] = test_df['user_id'].astype(int)\n",
    "test_df['item_id'] = test_df['item_id'].astype(int)\n",
    "test_df['interaction'] = test_df['interaction'].astype(float)\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Prepare data for model\n",
    "n_user_id = df['user_id'].nunique()\n",
    "n_item_id = df['item_id'].nunique()\n",
    "user_features_col = [f'userfeature{i}' for i in range(n_features)]\n",
    "item_features_col = [f'itemfeature{i}' for i in range(n_features)]\n",
    "\n",
    "# DeepFM Model\n",
    "def create_deepfm_model():\n",
    "    # Inputs\n",
    "    user_input = Input(shape=(1,), name='user_id')\n",
    "    item_input = Input(shape=(1,), name='item_id')\n",
    "    user_features_input = Input(shape=(n_features,), name='user_features')\n",
    "    item_features_input = Input(shape=(n_features,), name='item_features')\n",
    "\n",
    "    # Embeddings for FM\n",
    "    user_embedding = Embedding(input_dim=n_user_id, output_dim=8)(user_input)\n",
    "    item_embedding = Embedding(input_dim=n_item_id, output_dim=8)(item_input)\n",
    "    user_embedding = Flatten()(user_embedding)\n",
    "    item_embedding = Flatten()(item_embedding)\n",
    "    fm_part = Add()([user_embedding, item_embedding])\n",
    "    \n",
    "    # Concatenate for DNN\n",
    "    dnn_input = concatenate([user_embedding, item_embedding, user_features_input, item_features_input])\n",
    "    dnn_part = Dense(64, activation='relu')(dnn_input)\n",
    "    dnn_part = Dense(32, activation='relu')(dnn_part)\n",
    "    dnn_part = Dense(16, activation='relu')(dnn_part)\n",
    "    \n",
    "    # Final layer\n",
    "    concat_part = concatenate([fm_part, dnn_part])\n",
    "    output = Dense(1, activation='sigmoid')(concat_part)\n",
    "\n",
    "    model = Model(inputs=[user_input, item_input, user_features_input, item_features_input], outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = create_deepfm_model()\n",
    "model.summary()\n",
    "\n",
    "# Prepare input data\n",
    "train_input = [train_df['user_id'], train_df['item_id'], train_df[user_features_col], train_df[item_features_col]]\n",
    "train_labels = train_df['interaction']\n",
    "test_input = [test_df['user_id'], test_df['item_id'], test_df[user_features_col], test_df[item_features_col]]\n",
    "test_labels = test_df['interaction']\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_input, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_input, test_labels)\n",
    "print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167b6948",
   "metadata": {},
   "source": [
    "# Sequential Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf65274a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (3500, 23)\n",
      "Test set shape: (1500, 23)\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/anaconda3/lib/python3.10/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.0575 - loss: 6.3320 - val_accuracy: 0.1050 - val_loss: 4.8004\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1526 - loss: 4.3688 - val_accuracy: 0.2550 - val_loss: 3.9201\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2566 - loss: 3.4180 - val_accuracy: 0.2950 - val_loss: 3.1630\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.2763 - loss: 2.9275 - val_accuracy: 0.3350 - val_loss: 3.0383\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3107 - loss: 2.8168 - val_accuracy: 0.3600 - val_loss: 2.9233\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3586 - loss: 2.6660 - val_accuracy: 0.4000 - val_loss: 2.8082\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3862 - loss: 2.5869 - val_accuracy: 0.4300 - val_loss: 2.6917\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4398 - loss: 2.3774 - val_accuracy: 0.5350 - val_loss: 2.6196\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5188 - loss: 2.3087 - val_accuracy: 0.6000 - val_loss: 2.5243\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5749 - loss: 2.2329 - val_accuracy: 0.6100 - val_loss: 2.3871\n",
      "Epoch 1/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.0256 - loss: 7.6764 - val_accuracy: 0.0500 - val_loss: 5.9218\n",
      "Epoch 2/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0564 - loss: 6.1116 - val_accuracy: 0.1250 - val_loss: 5.7737\n",
      "Epoch 3/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0965 - loss: 5.7784 - val_accuracy: 0.1250 - val_loss: 5.4906\n",
      "Epoch 4/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.1143 - loss: 5.7125 - val_accuracy: 0.1250 - val_loss: 5.4087\n",
      "Epoch 5/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.1112 - loss: 5.5210 - val_accuracy: 0.1250 - val_loss: 5.3299\n",
      "Epoch 6/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1079 - loss: 5.4741 - val_accuracy: 0.1250 - val_loss: 5.2584\n",
      "Epoch 7/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1185 - loss: 5.3794 - val_accuracy: 0.1250 - val_loss: 5.1997\n",
      "Epoch 8/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1091 - loss: 5.3456 - val_accuracy: 0.1250 - val_loss: 5.1154\n",
      "Epoch 9/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0996 - loss: 5.2636 - val_accuracy: 0.1000 - val_loss: 4.8369\n",
      "Epoch 10/10\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0993 - loss: 5.2620 - val_accuracy: 0.1000 - val_loss: 4.5650\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.1277 - loss: 8.7754\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.0260 - loss: 10.7418\n",
      "RNN Model - Test Loss: 8.944633483886719\n",
      "RNN Model - Test Accuracy: 0.11800000816583633\n",
      "Transformer Model - Test Loss: 10.994032859802246\n",
      "Transformer Model - Test Accuracy: 0.02500000223517418\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Top 5 RNN recommendations for user 0: [ 0 49 21 17 33]\n",
      "Top 5 Transformer recommendations for user 0: [49 44  0 46 48]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "RNN Model:\n",
      "Precision@5: 0.1280\n",
      "Recall@5: 0.0711\n",
      "F1 Score: 0.0914\n",
      "\n",
      "Transformer Model:\n",
      "Precision@5: 0.2180\n",
      "Recall@5: 0.1214\n",
      "F1 Score: 0.1559\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate user data\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "n_features = 10\n",
    "\n",
    "# Create user features\n",
    "user_features = np.random.rand(n_users, n_features)\n",
    "\n",
    "# Create item features\n",
    "item_features = np.random.rand(n_items, n_features)\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = np.random.randint(0, 2, size=(n_users, n_items))\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'user_id': np.repeat(np.arange(n_users), n_items),\n",
    "    'item_id': np.tile(np.arange(n_items), n_users),\n",
    "    'interaction': interaction_matrix.flatten()\n",
    "})\n",
    "\n",
    "# Add user and item features to the DataFrame\n",
    "for i in range(n_features):\n",
    "    df[f'user_feature_{i}'] = np.repeat(user_features[:, i], n_items)\n",
    "    df[f'item_feature_{i}'] = np.tile(item_features[:, i], n_users)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "train_df['user_id'] = train_df['user_id'].astype(int)\n",
    "train_df['item_id'] = train_df['item_id'].astype(int)\n",
    "train_df['interaction'] = train_df['interaction'].astype(float)\n",
    "\n",
    "test_df['user_id'] = test_df['user_id'].astype(int)\n",
    "test_df['item_id'] = test_df['item_id'].astype(int)\n",
    "test_df['interaction'] = test_df['interaction'].astype(float)\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Sort the dataframe by user_id and item_id\n",
    "    df = df.sort_values(['user_id', 'item_id'])\n",
    "    \n",
    "    # Create sequences of item interactions for each user\n",
    "    sequences = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        sequences[row['user_id']].append(row['item_id'])\n",
    "    \n",
    "    # Pad sequences to a fixed length\n",
    "    max_sequence_length = 10\n",
    "    padded_sequences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        list(sequences.values()), maxlen=max_sequence_length, padding='pre'\n",
    "    )\n",
    "    \n",
    "    # Create labels (next item in the sequence)\n",
    "    labels = np.zeros_like(padded_sequences)\n",
    "    labels[:, :-1] = padded_sequences[:, 1:]\n",
    "    labels[:, -1] = 0  # Set the last label to 0 (no next item)\n",
    "    \n",
    "    return padded_sequences, labels\n",
    "\n",
    "# Preprocess train and test data\n",
    "train_sequences, train_labels = preprocess_data(train_df)\n",
    "test_sequences, test_labels = preprocess_data(test_df)\n",
    "\n",
    "# Normalize user and item features\n",
    "feature_names = [f'user_feature_{i}' for i in range(n_features)] + [f'item_feature_{i}' for i in range(n_features)]\n",
    "normalizer = StandardScaler()\n",
    "train_df[feature_names] = normalizer.fit_transform(train_df[feature_names])\n",
    "test_df[feature_names] = normalizer.transform(test_df[feature_names])\n",
    "\n",
    "# Create user and item embeddings\n",
    "n_users = train_df['user_id'].nunique()\n",
    "n_items = train_df['item_id'].nunique()\n",
    "embedding_dim = 32\n",
    "\n",
    "user_embedding = tf.keras.layers.Embedding(n_users, embedding_dim, input_length=1, name='user_embedding')\n",
    "item_embedding = tf.keras.layers.Embedding(n_items, embedding_dim, input_length=1, name='item_embedding')\n",
    "\n",
    "# Now let's implement both RNN and Transformer models\n",
    "\n",
    "# 1. RNN-based Sequential Model\n",
    "class RNNSequentialModel(Model):\n",
    "    def __init__(self, n_items, embedding_dim, rnn_units):\n",
    "        super(RNNSequentialModel, self).__init__()\n",
    "        self.item_embedding = tf.keras.layers.Embedding(n_items, embedding_dim)\n",
    "        self.rnn = tf.keras.layers.GRU(rnn_units, return_sequences=True)\n",
    "        self.dense = tf.keras.layers.Dense(n_items)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.item_embedding(inputs)\n",
    "        x = self.rnn(x)\n",
    "        return self.dense(x)\n",
    "\n",
    "# 2. Transformer-based Sequential Model\n",
    "class TransformerSequentialModel(Model):\n",
    "    def __init__(self, n_items, embedding_dim, num_heads, ff_dim, max_sequence_length):\n",
    "        super(TransformerSequentialModel, self).__init__()\n",
    "        self.item_embedding = tf.keras.layers.Embedding(n_items, embedding_dim)\n",
    "        self.pos_encoding = self.positional_encoding(max_sequence_length, embedding_dim)\n",
    "        self.transformer_block = TransformerBlock(embedding_dim, num_heads, ff_dim)\n",
    "        self.dense = tf.keras.layers.Dense(n_items)\n",
    "        \n",
    "    def call(self, inputs, training=False):\n",
    "        x = self.item_embedding(inputs)\n",
    "        x += self.pos_encoding[:, :tf.shape(x)[1], :]\n",
    "        x = self.transformer_block(x, training=training)\n",
    "        return self.dense(x)\n",
    "    \n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angles = np.arange(position)[:, np.newaxis] / np.power(10000, (2 * (np.arange(d_model)[np.newaxis, :] // 2)) / np.float32(d_model))\n",
    "        sines = np.sin(angles[:, 0::2])\n",
    "        cosines = np.cos(angles[:, 1::2])\n",
    "        pos_encoding = np.concatenate([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[np.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, dtype=tf.float32)\n",
    "\n",
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "# Create and compile the models\n",
    "rnn_model = RNNSequentialModel(n_items, embedding_dim, rnn_units=64)\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "transformer_model = TransformerSequentialModel(n_items, embedding_dim, num_heads=4, ff_dim=64, max_sequence_length=10)\n",
    "transformer_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the models\n",
    "rnn_history = rnn_model.fit(train_sequences, train_labels, epochs=10, validation_split=0.2, batch_size=32)\n",
    "transformer_history = transformer_model.fit(train_sequences, train_labels, epochs=10, validation_split=0.2, batch_size=32)\n",
    "\n",
    "# Evaluate the models\n",
    "rnn_loss, rnn_accuracy = rnn_model.evaluate(test_sequences, test_labels)\n",
    "transformer_loss, transformer_accuracy = transformer_model.evaluate(test_sequences, test_labels)\n",
    "\n",
    "print(\"RNN Model - Test Loss:\", rnn_loss)\n",
    "print(\"RNN Model - Test Accuracy:\", rnn_accuracy)\n",
    "print(\"Transformer Model - Test Loss:\", transformer_loss)\n",
    "print(\"Transformer Model - Test Accuracy:\", transformer_accuracy)\n",
    "\n",
    "# Function to get recommendations\n",
    "def get_recommendations(model, user_sequence, n_recommendations=5):\n",
    "    predictions = model.predict(np.expand_dims(user_sequence, axis=0))\n",
    "    top_items = np.argsort(predictions[0, -1])[-n_recommendations:][::-1]\n",
    "    return top_items\n",
    "\n",
    "# Get recommendations for a user\n",
    "user_id = 0\n",
    "user_sequence = train_sequences[user_id]\n",
    "rnn_recommendations = get_recommendations(rnn_model, user_sequence)\n",
    "transformer_recommendations = get_recommendations(transformer_model, user_sequence)\n",
    "\n",
    "print(f\"Top 5 RNN recommendations for user {user_id}: {rnn_recommendations}\")\n",
    "print(f\"Top 5 Transformer recommendations for user {user_id}: {transformer_recommendations}\")\n",
    "\n",
    "# Evaluate recommendations\n",
    "def evaluate_recommendations(model, test_sequences, test_labels, n_recommendations=5):\n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    f1_list = []\n",
    "    \n",
    "    for user_sequence, true_next_items in zip(test_sequences, test_labels):\n",
    "        recommended_items = get_recommendations(model, user_sequence, n_recommendations)\n",
    "        true_next_items = true_next_items[true_next_items != 0]  # Remove padding\n",
    "        \n",
    "        precision = len(set(recommended_items) & set(true_next_items)) / len(recommended_items)\n",
    "        recall = len(set(recommended_items) & set(true_next_items)) / len(true_next_items)\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        \n",
    "        if precision + recall > 0:\n",
    "            f1 = 2 * (precision * recall) / (precision + recall)\n",
    "        else:\n",
    "            f1 = 0\n",
    "        f1_list.append(f1)\n",
    "    \n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    avg_f1 = np.mean(f1_list)\n",
    "    \n",
    "    return avg_precision, avg_recall, avg_f1\n",
    "\n",
    "rnn_precision, rnn_recall, rnn_f1 = evaluate_recommendations(rnn_model, test_sequences, test_labels)\n",
    "transformer_precision, transformer_recall, transformer_f1 = evaluate_recommendations(transformer_model, test_sequences, test_labels)\n",
    "\n",
    "print(\"RNN Model:\")\n",
    "print(f\"Precision@5: {rnn_precision:.4f}\")\n",
    "print(f\"Recall@5: {rnn_recall:.4f}\")\n",
    "print(f\"F1 Score: {rnn_f1:.4f}\")\n",
    "\n",
    "print(\"\\nTransformer Model:\")\n",
    "print(f\"Precision@5: {transformer_precision:.4f}\")\n",
    "print(f\"Recall@5: {transformer_recall:.4f}\")\n",
    "print(f\"F1 Score: {transformer_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0fca065",
   "metadata": {},
   "source": [
    "# Ensembles of collaborative filtering, content-based, and knowledge-based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78a0a63b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@5: 0.1100\n",
      "Recall@5: 0.0349\n",
      "F1 Score: 0.0530\n",
      "Top 5 recommendations for user 0: [25  7 20 29 11]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from surprise import SVD, Dataset, Reader\n",
    "from surprise.model_selection import train_test_split as surprise_split\n",
    "\n",
    "# Assume the data simulation code you provided is already run\n",
    "# and we have train_df and test_df\n",
    "\n",
    "# 1. Collaborative Filtering Model (using Surprise library)\n",
    "def collaborative_filtering_model(train_df, test_df):\n",
    "    reader = Reader(rating_scale=(0, 1))\n",
    "    data = Dataset.load_from_df(train_df[['user_id', 'item_id', 'interaction']], reader)\n",
    "    trainset, _ = surprise_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = SVD(n_factors=20, n_epochs=20, lr_all=0.005, reg_all=0.02)\n",
    "    model.fit(trainset)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 2. Content-Based Model\n",
    "def content_based_model(train_df, test_df):\n",
    "    feature_cols = [col for col in train_df.columns if col.startswith('item_feature_')]\n",
    "    item_features = train_df.groupby('item_id')[feature_cols].mean()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    item_features_scaled = scaler.fit_transform(item_features)\n",
    "    \n",
    "    item_similarity = cosine_similarity(item_features_scaled)\n",
    "    \n",
    "    return item_similarity, item_features.index\n",
    "\n",
    "# 3. Knowledge-Based Model (simple popularity-based model)\n",
    "def knowledge_based_model(train_df):\n",
    "    item_popularity = train_df.groupby('item_id')['interaction'].sum().sort_values(ascending=False)\n",
    "    return item_popularity\n",
    "\n",
    "# Ensemble Model\n",
    "class EnsembleRecommender:\n",
    "    def __init__(self, cf_model, cb_model, kb_model, item_ids):\n",
    "        self.cf_model = cf_model\n",
    "        self.cb_model, self.item_ids = cb_model\n",
    "        self.kb_model = kb_model\n",
    "        self.item_ids = item_ids\n",
    "    \n",
    "    def recommend(self, user_id, n_recommendations=5):\n",
    "        # Collaborative Filtering predictions\n",
    "        cf_predictions = [self.cf_model.predict(user_id, item_id).est for item_id in self.item_ids]\n",
    "        \n",
    "        # Content-Based predictions\n",
    "        user_interacted_items = train_df[train_df['user_id'] == user_id]['item_id'].values\n",
    "        if len(user_interacted_items) > 0:\n",
    "            user_profile = self.cb_model[user_interacted_items].mean(axis=0)\n",
    "            cb_predictions = cosine_similarity([user_profile], self.cb_model)[0]\n",
    "        else:\n",
    "            cb_predictions = np.zeros(len(self.item_ids))\n",
    "        \n",
    "        # Knowledge-Based predictions (normalized popularity scores)\n",
    "        kb_predictions = self.kb_model.values / self.kb_model.max()\n",
    "        \n",
    "        # Ensemble predictions (simple average)\n",
    "        ensemble_predictions = (np.array(cf_predictions) + cb_predictions + kb_predictions) / 3\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_items = self.item_ids[np.argsort(ensemble_predictions)[::-1][:n_recommendations]]\n",
    "        \n",
    "        return top_items\n",
    "\n",
    "# Train individual models\n",
    "cf_model = collaborative_filtering_model(train_df, test_df)\n",
    "cb_model = content_based_model(train_df, test_df)\n",
    "kb_model = knowledge_based_model(train_df)\n",
    "\n",
    "# Create ensemble recommender\n",
    "ensemble = EnsembleRecommender(cf_model, cb_model, kb_model, np.sort(train_df['item_id'].unique()))\n",
    "\n",
    "# Function to evaluate recommendations\n",
    "def evaluate_recommendations(recommender, test_df, n_recommendations=5):\n",
    "    user_item_interactions = test_df.groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "    \n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for user_id in user_item_interactions.keys():\n",
    "        true_items = set(user_item_interactions[user_id])\n",
    "        recommended_items = set(recommender.recommend(user_id, n_recommendations))\n",
    "        \n",
    "        precision = len(true_items.intersection(recommended_items)) / len(recommended_items)\n",
    "        recall = len(true_items.intersection(recommended_items)) / len(true_items)\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, f1_score\n",
    "\n",
    "# Evaluate the ensemble recommender\n",
    "precision, recall, f1 = evaluate_recommendations(ensemble, test_df)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Get recommendations for a sample user\n",
    "sample_user_id = 0\n",
    "recommendations = ensemble.recommend(sample_user_id)\n",
    "print(f\"Top 5 recommendations for user {sample_user_id}: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe98d1",
   "metadata": {},
   "source": [
    "# Combining shallow and deep models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde30ac5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4901 - loss: 1.3146 - val_accuracy: 0.4957 - val_loss: 1.1321\n",
      "Epoch 2/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.5260 - loss: 1.0811 - val_accuracy: 0.4957 - val_loss: 0.9697\n",
      "Epoch 3/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.5540 - loss: 0.9323 - val_accuracy: 0.4843 - val_loss: 0.8670\n",
      "Epoch 4/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.5690 - loss: 0.8351 - val_accuracy: 0.4800 - val_loss: 0.8025\n",
      "Epoch 5/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.5805 - loss: 0.7712 - val_accuracy: 0.4743 - val_loss: 0.7643\n",
      "Epoch 6/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.5967 - loss: 0.7330 - val_accuracy: 0.4657 - val_loss: 0.7424\n",
      "Epoch 7/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.5883 - loss: 0.7078 - val_accuracy: 0.4643 - val_loss: 0.7312\n",
      "Epoch 8/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - accuracy: 0.5722 - loss: 0.6940 - val_accuracy: 0.4686 - val_loss: 0.7248\n",
      "Epoch 9/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.5931 - loss: 0.6792 - val_accuracy: 0.4643 - val_loss: 0.7233\n",
      "Epoch 10/10\n",
      "\u001b[1m44/44\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.5786 - loss: 0.6764 - val_accuracy: 0.4657 - val_loss: 0.7223\n",
      "\u001b[1m47/47\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327us/step - accuracy: 0.4903 - loss: 0.7184\n",
      "Test Loss: 0.7187\n",
      "Test Accuracy: 0.4973\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Assume the data simulation code you provided is already run\n",
    "# and we have train_df and test_df\n",
    "\n",
    "# Preprocess the data\n",
    "def preprocess_data(df):\n",
    "    # Normalize user and item features\n",
    "    feature_cols = [col for col in df.columns if col.startswith('user_feature_') or col.startswith('item_feature_')]\n",
    "    scaler = StandardScaler()\n",
    "    df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "    \n",
    "    # Create input arrays\n",
    "    user_ids = df['user_id'].values\n",
    "    item_ids = df['item_id'].values\n",
    "    features = df[feature_cols].values\n",
    "    labels = df['interaction'].values\n",
    "    \n",
    "    return user_ids, item_ids, features, labels\n",
    "\n",
    "# Create the Wide & Deep model\n",
    "class WideAndDeepModel(Model):\n",
    "    def __init__(self, n_users, n_items, n_features, embedding_dim=16, hidden_units=[64, 32]):\n",
    "        super(WideAndDeepModel, self).__init__()\n",
    "        \n",
    "        # Wide part\n",
    "        self.user_embedding = layers.Embedding(n_users, embedding_dim)\n",
    "        self.item_embedding = layers.Embedding(n_items, embedding_dim)\n",
    "        self.wide = layers.Dense(1)\n",
    "        \n",
    "        # Deep part\n",
    "        self.deep_inputs = layers.Dense(embedding_dim, activation='relu')\n",
    "        self.deep_layers = [layers.Dense(units, activation='relu', kernel_regularizer=l2(0.01)) for units in hidden_units]\n",
    "        self.deep_output = layers.Dense(1)\n",
    "        \n",
    "        # Combine wide and deep\n",
    "        self.combine = layers.Add()\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        user_id, item_id, features = inputs\n",
    "        \n",
    "        # Wide part\n",
    "        user_embed = self.user_embedding(user_id)\n",
    "        item_embed = self.item_embedding(item_id)\n",
    "        wide = self.wide(tf.concat([user_embed, item_embed], axis=1))\n",
    "        \n",
    "        # Deep part\n",
    "        deep = self.deep_inputs(features)\n",
    "        for layer in self.deep_layers:\n",
    "            deep = layer(deep)\n",
    "        deep = self.deep_output(deep)\n",
    "        \n",
    "        # Combine wide and deep\n",
    "        output = self.combine([wide, deep])\n",
    "        return tf.sigmoid(output)\n",
    "\n",
    "# Prepare the data\n",
    "train_user_ids, train_item_ids, train_features, train_labels = preprocess_data(train_df)\n",
    "test_user_ids, test_item_ids, test_features, test_labels = preprocess_data(test_df)\n",
    "\n",
    "# Create and compile the model\n",
    "n_users = train_df['user_id'].nunique()\n",
    "n_items = train_df['item_id'].nunique()\n",
    "n_features = train_features.shape[1]\n",
    "\n",
    "model = WideAndDeepModel(n_users, n_items, n_features)\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    [train_user_ids, train_item_ids, train_features],\n",
    "    train_labels,\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate([test_user_ids, test_item_ids, test_features], test_labels)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60285bdc",
   "metadata": {},
   "source": [
    "# Multi-task learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1a1a250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set shape: (3500, 24)\n",
      "Test set shape: (1500, 24)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate user data\n",
    "n_users = 100\n",
    "n_items = 50\n",
    "n_features = 10\n",
    "\n",
    "# Create user features\n",
    "user_features = np.random.rand(n_users, n_features)\n",
    "\n",
    "# Create item features\n",
    "item_features = np.random.rand(n_items, n_features)\n",
    "\n",
    "# Create user-item interaction matrix\n",
    "interaction_matrix = np.random.randint(0, 2, size=(n_users, n_items))\n",
    "\n",
    "# Simulate secondary task labels (e.g., user preference for item categories)\n",
    "secondary_task_labels = np.random.randint(0, 5, size=(n_users, n_items))\n",
    "\n",
    "# Create a DataFrame for easier manipulation\n",
    "df = pd.DataFrame({\n",
    "    'user_id': np.repeat(np.arange(n_users), n_items),\n",
    "    'item_id': np.tile(np.arange(n_items), n_users),\n",
    "    'interaction': interaction_matrix.flatten(),\n",
    "    'secondary_task': secondary_task_labels.flatten()\n",
    "})\n",
    "\n",
    "# Add some user and item features\n",
    "for i in range(n_features):\n",
    "    df[f'userfeature{i}'] = np.repeat(user_features[:, i], n_items)\n",
    "    df[f'itemfeature{i}'] = np.tile(item_features[:, i], n_users)\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)\n",
    "\n",
    "# Ensure correct data types\n",
    "train_df['user_id'] = train_df['user_id'].astype(int)\n",
    "train_df['item_id'] = train_df['item_id'].astype(int)\n",
    "train_df['interaction'] = train_df['interaction'].astype(float)\n",
    "test_df['user_id'] = test_df['user_id'].astype(int)\n",
    "test_df['item_id'] = test_df['item_id'].astype(int)\n",
    "test_df['interaction'] = test_df['interaction'].astype(float)\n",
    "\n",
    "print(f\"Train set shape: {train_df.shape}\")\n",
    "print(f\"Test set shape: {test_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02cf0d93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ user_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_id             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_6         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> â”‚ user_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_7         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)      â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> â”‚ item_id[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ user_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_features       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_4       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ flatten_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ flatten_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ user_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ item_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> â”‚ concatenate_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ interaction_output  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ secondary_task_outâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">165</span> â”‚ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ user_id             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_id             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_6         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚        \u001b[38;5;34m800\u001b[0m â”‚ user_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ embedding_7         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m8\u001b[0m)      â”‚        \u001b[38;5;34m400\u001b[0m â”‚ item_id[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mEmbedding\u001b[0m)         â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         â”‚          \u001b[38;5;34m0\u001b[0m â”‚ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ user_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ item_features       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_4       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ flatten_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ flatten_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ user_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ item_features[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_20 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m2,368\u001b[0m â”‚ concatenate_4[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_21 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ interaction_output  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ secondary_task_outâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)         â”‚        \u001b[38;5;34m165\u001b[0m â”‚ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mDense\u001b[0m)             â”‚                   â”‚            â”‚                   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,846</span> (22.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,846\u001b[0m (22.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,846</span> (22.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,846\u001b[0m (22.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - interaction_output_accuracy: 0.4866 - loss: 2.3165 - secondary_task_output_accuracy: 0.2009 - val_interaction_output_accuracy: 0.5157 - val_loss: 2.3051 - val_secondary_task_output_accuracy: 0.1943\n",
      "Epoch 2/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - interaction_output_accuracy: 0.5049 - loss: 2.3002 - secondary_task_output_accuracy: 0.2277 - val_interaction_output_accuracy: 0.5157 - val_loss: 2.3070 - val_secondary_task_output_accuracy: 0.1886\n",
      "Epoch 3/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - interaction_output_accuracy: 0.5346 - loss: 2.2922 - secondary_task_output_accuracy: 0.2179 - val_interaction_output_accuracy: 0.5171 - val_loss: 2.3104 - val_secondary_task_output_accuracy: 0.1886\n",
      "Epoch 4/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 685us/step - interaction_output_accuracy: 0.5402 - loss: 2.2860 - secondary_task_output_accuracy: 0.2375 - val_interaction_output_accuracy: 0.5314 - val_loss: 2.3119 - val_secondary_task_output_accuracy: 0.1943\n",
      "Epoch 5/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 611us/step - interaction_output_accuracy: 0.5731 - loss: 2.2705 - secondary_task_output_accuracy: 0.2576 - val_interaction_output_accuracy: 0.5086 - val_loss: 2.3206 - val_secondary_task_output_accuracy: 0.2057\n",
      "Epoch 6/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592us/step - interaction_output_accuracy: 0.5626 - loss: 2.2603 - secondary_task_output_accuracy: 0.2718 - val_interaction_output_accuracy: 0.4971 - val_loss: 2.3348 - val_secondary_task_output_accuracy: 0.2100\n",
      "Epoch 7/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 595us/step - interaction_output_accuracy: 0.5785 - loss: 2.2419 - secondary_task_output_accuracy: 0.2891 - val_interaction_output_accuracy: 0.4871 - val_loss: 2.3450 - val_secondary_task_output_accuracy: 0.1771\n",
      "Epoch 8/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 624us/step - interaction_output_accuracy: 0.5970 - loss: 2.2298 - secondary_task_output_accuracy: 0.3053 - val_interaction_output_accuracy: 0.4786 - val_loss: 2.3591 - val_secondary_task_output_accuracy: 0.1929\n",
      "Epoch 9/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 606us/step - interaction_output_accuracy: 0.5925 - loss: 2.2244 - secondary_task_output_accuracy: 0.2916 - val_interaction_output_accuracy: 0.4757 - val_loss: 2.3686 - val_secondary_task_output_accuracy: 0.1843\n",
      "Epoch 10/10\n",
      "\u001b[1m88/88\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 614us/step - interaction_output_accuracy: 0.5922 - loss: 2.2166 - secondary_task_output_accuracy: 0.2932 - val_interaction_output_accuracy: 0.4829 - val_loss: 2.3749 - val_secondary_task_output_accuracy: 0.1914\n",
      "\u001b[1m47/47\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 344us/step - interaction_output_accuracy: 0.4890 - loss: 2.3484 - secondary_task_output_accuracy: 0.2249\n",
      "loss: 2.3550236225128174\n",
      "compile_metrics: 0.492000013589859\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Prepare input data\n",
    "user_features_col = [f'userfeature{i}' for i in range(n_features)]\n",
    "item_features_col = [f'itemfeature{i}' for i in range(n_features)]\n",
    "\n",
    "n_user_id = df['user_id'].nunique()\n",
    "n_item_id = df['item_id'].nunique()\n",
    "\n",
    "def create_mtl_model():\n",
    "    # Inputs\n",
    "    user_input = Input(shape=(1,), name='user_id')\n",
    "    item_input = Input(shape=(1,), name='item_id')\n",
    "    user_features_input = Input(shape=(n_features,), name='user_features')\n",
    "    item_features_input = Input(shape=(n_features,), name='item_features')\n",
    "\n",
    "    # Embeddings for user and item\n",
    "    user_embedding = Embedding(input_dim=n_user_id, output_dim=8)(user_input)\n",
    "    item_embedding = Embedding(input_dim=n_item_id, output_dim=8)(item_input)\n",
    "    user_embedding = Flatten()(user_embedding)\n",
    "    item_embedding = Flatten()(item_embedding)\n",
    "\n",
    "    # Concatenate embeddings and features\n",
    "    concat_input = concatenate([user_embedding, item_embedding, user_features_input, item_features_input])\n",
    "\n",
    "    # Shared layers\n",
    "    shared = Dense(64, activation='relu')(concat_input)\n",
    "    shared = Dense(32, activation='relu')(shared)\n",
    "\n",
    "    # Task 1: Interaction prediction\n",
    "    interaction_output = Dense(1, activation='sigmoid', name='interaction_output')(shared)\n",
    "\n",
    "    # Task 2: Secondary task prediction\n",
    "    secondary_task_output = Dense(5, activation='softmax', name='secondary_task_output')(shared)\n",
    "\n",
    "    # Define model\n",
    "    model = Model(inputs=[user_input, item_input, user_features_input, item_features_input],\n",
    "                  outputs=[interaction_output, secondary_task_output])\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'interaction_output': 'binary_crossentropy', 'secondary_task_output': 'sparse_categorical_crossentropy'},\n",
    "                  metrics={'interaction_output': 'accuracy', 'secondary_task_output': 'accuracy'})\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = create_mtl_model()\n",
    "model.summary()\n",
    "\n",
    "# Prepare input data\n",
    "train_input = [train_df['user_id'], train_df['item_id'], train_df[user_features_col], train_df[item_features_col]]\n",
    "train_labels = {'interaction_output': train_df['interaction'], 'secondary_task_output': train_df['secondary_task']}\n",
    "test_input = [test_df['user_id'], test_df['item_id'], test_df[user_features_col], test_df[item_features_col]]\n",
    "test_labels = {'interaction_output': test_df['interaction'], 'secondary_task_output': test_df['secondary_task']}\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_input, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model.evaluate(test_input, test_labels)\n",
    "\n",
    "# Print the results\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b8573e",
   "metadata": {},
   "source": [
    "# Contextual bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a756b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No feature columns found. Returning original dataframe.\n",
      "Warning: No feature columns found. Returning original dataframe.\n",
      "Train DataFrame columns: ['user_id', 'item_id', 'interaction', 'secondary_task', 'userfeature0', 'itemfeature0', 'userfeature1', 'itemfeature1', 'userfeature2', 'itemfeature2', 'userfeature3', 'itemfeature3', 'userfeature4', 'itemfeature4', 'userfeature5', 'itemfeature5', 'userfeature6', 'itemfeature6', 'userfeature7', 'itemfeature7', 'userfeature8', 'itemfeature8', 'userfeature9', 'itemfeature9']\n",
      "Test DataFrame columns: ['user_id', 'item_id', 'interaction', 'secondary_task', 'userfeature0', 'itemfeature0', 'userfeature1', 'itemfeature1', 'userfeature2', 'itemfeature2', 'userfeature3', 'itemfeature3', 'userfeature4', 'itemfeature4', 'userfeature5', 'itemfeature5', 'userfeature6', 'itemfeature6', 'userfeature7', 'itemfeature7', 'userfeature8', 'itemfeature8', 'userfeature9', 'itemfeature9']\n",
      "Training - Total Reward: 38.0\n",
      "Training - Accuracy: 0.0206\n",
      "Testing - Total Reward: 17.0\n",
      "Testing - Accuracy: 0.0187\n",
      "Top 5 recommendations for user 0: [0, 1, 2, 3, 4]\n",
      "Precision@5: 0.1480\n",
      "Recall@5: 0.0879\n",
      "F1 Score: 0.1103\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assume the data simulation code is already run and we have train_df and test_df\n",
    "\n",
    "class LinUCBArm:\n",
    "    def __init__(self, arm_index, d, alpha):\n",
    "        self.arm_index = arm_index\n",
    "        self.A = np.identity(d)\n",
    "        self.b = np.zeros((d, 1))\n",
    "        self.A_inv = np.identity(d)\n",
    "        self.theta = np.zeros((d, 1))\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def update(self, x, reward):\n",
    "        x = x.reshape(-1, 1)  # Ensure x is a column vector\n",
    "        self.A += x.dot(x.T)\n",
    "        self.b += reward * x\n",
    "        self.A_inv = np.linalg.inv(self.A)\n",
    "        self.theta = self.A_inv.dot(self.b)\n",
    "\n",
    "    def compute_ucb(self, x):\n",
    "        x = x.reshape(-1, 1)  # Ensure x is a column vector\n",
    "        mean = float(x.T.dot(self.theta))\n",
    "        var = float(self.alpha * np.sqrt(x.T.dot(self.A_inv).dot(x)))\n",
    "        ucb = mean + var\n",
    "        return ucb\n",
    "\n",
    "class LinUCBPolicy:\n",
    "    def __init__(self, n_arms, d, alpha):\n",
    "        self.arms = [LinUCBArm(i, d, alpha) for i in range(n_arms)]\n",
    "        self.n_arms = n_arms\n",
    "        self.d = d\n",
    "\n",
    "    def select_arm(self, context):\n",
    "        ucb_values = [arm.compute_ucb(context) for arm in self.arms]\n",
    "        return np.argmax(ucb_values)\n",
    "\n",
    "    def update(self, arm_index, context, reward):\n",
    "        self.arms[arm_index].update(context, reward)\n",
    "\n",
    "def preprocess_data(df):\n",
    "    user_feature_cols = [col for col in df.columns if col.startswith('user_feature_')]\n",
    "    item_feature_cols = [col for col in df.columns if col.startswith('item_feature_')]\n",
    "    \n",
    "    feature_cols = user_feature_cols + item_feature_cols\n",
    "    \n",
    "    if feature_cols:\n",
    "        scaler = StandardScaler()\n",
    "        df[feature_cols] = scaler.fit_transform(df[feature_cols])\n",
    "    else:\n",
    "        print(\"Warning: No feature columns found. Returning original dataframe.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_contextual_bandit(policy, data, n_rounds):\n",
    "    total_reward = 0\n",
    "    correct_recommendations = 0\n",
    "\n",
    "    for t in range(n_rounds):\n",
    "        context = data.iloc[t]\n",
    "        arm_features = context[[f'item_feature_{i}' for i in range(n_features)]].values\n",
    "        user_features = context[[f'user_feature_{i}' for i in range(n_features)]].values\n",
    "        combined_features = np.concatenate([user_features, arm_features])\n",
    "\n",
    "        selected_arm = policy.select_arm(combined_features)\n",
    "        reward = context['interaction'] if selected_arm == context['item_id'] else 0\n",
    "\n",
    "        policy.update(selected_arm, combined_features, reward)\n",
    "        total_reward += reward\n",
    "        correct_recommendations += (selected_arm == context['item_id'])\n",
    "\n",
    "    return total_reward, correct_recommendations\n",
    "\n",
    "def get_recommendations(policy, user_id, n_recommendations=5):\n",
    "    user_data = test_df[test_df['user_id'] == user_id].iloc[0]\n",
    "    user_features = user_data[[f'user_feature_{i}' for i in range(n_features)]].values\n",
    "\n",
    "    item_scores = []\n",
    "    for item_id in range(n_items):\n",
    "        item_features = test_df[test_df['item_id'] == item_id][[f'item_feature_{i}' for i in range(n_features)]].iloc[0].values\n",
    "        combined_features = np.concatenate([user_features, item_features])\n",
    "        ucb = policy.arms[item_id].compute_ucb(combined_features)\n",
    "        item_scores.append((item_id, ucb))\n",
    "\n",
    "    item_scores.sort(key=lambda x: x[1], reverse=True)\n",
    "    return [item_id for item_id, _ in item_scores[:n_recommendations]]\n",
    "\n",
    "def evaluate_recommendations(policy, test_df, n_recommendations=5):\n",
    "    true_interactions = test_df[test_df['interaction'] == 1].groupby('user_id')['item_id'].apply(list).to_dict()\n",
    "    \n",
    "    precision_list = []\n",
    "    recall_list = []\n",
    "    \n",
    "    for user_id in true_interactions.keys():\n",
    "        recommended_items = get_recommendations(policy, user_id, n_recommendations)\n",
    "        true_items = set(true_interactions[user_id])\n",
    "        recommended_items = set(recommended_items)\n",
    "        \n",
    "        precision = len(true_items.intersection(recommended_items)) / len(recommended_items) if recommended_items else 0\n",
    "        recall = len(true_items.intersection(recommended_items)) / len(true_items) if true_items else 0\n",
    "        \n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "    \n",
    "    avg_precision = np.mean(precision_list)\n",
    "    avg_recall = np.mean(recall_list)\n",
    "    f1_score = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall) if (avg_precision + avg_recall) > 0 else 0\n",
    "    \n",
    "    return avg_precision, avg_recall, f1_score\n",
    "\n",
    "# Preprocess the data\n",
    "train_df = preprocess_data(train_df)\n",
    "test_df = preprocess_data(test_df)\n",
    "\n",
    "# Print column names to verify\n",
    "print(\"Train DataFrame columns:\", train_df.columns.tolist())\n",
    "print(\"Test DataFrame columns:\", test_df.columns.tolist())\n",
    "\n",
    "# Set n_features and n_items\n",
    "n_features = len([col for col in train_df.columns if col.startswith('user_feature_')])\n",
    "n_items = train_df['item_id'].nunique()\n",
    "\n",
    "# Initialize LinUCB policy\n",
    "d = 2 * n_features  # Combined user and item features\n",
    "alpha = 1.0  # Exploration parameter\n",
    "policy = LinUCBPolicy(n_items, d, alpha)\n",
    "\n",
    "# Run contextual bandit on training data\n",
    "n_rounds = len(train_df)\n",
    "train_reward, train_correct = run_contextual_bandit(policy, train_df, n_rounds)\n",
    "\n",
    "print(f\"Training - Total Reward: {train_reward}\")\n",
    "print(f\"Training - Accuracy: {train_correct / n_rounds:.4f}\")\n",
    "\n",
    "# Evaluate on test data\n",
    "n_rounds_test = len(test_df)\n",
    "test_reward, test_correct = run_contextual_bandit(policy, test_df, n_rounds_test)\n",
    "\n",
    "print(f\"Testing - Total Reward: {test_reward}\")\n",
    "print(f\"Testing - Accuracy: {test_correct / n_rounds_test:.4f}\")\n",
    "\n",
    "# Get recommendations for a sample user\n",
    "sample_user_id = 0\n",
    "recommendations = get_recommendations(policy, sample_user_id)\n",
    "print(f\"Top 5 recommendations for user {sample_user_id}: {recommendations}\")\n",
    "\n",
    "# Evaluate recommendations\n",
    "precision, recall, f1 = evaluate_recommendations(policy, test_df)\n",
    "print(f\"Precision@5: {precision:.4f}\")\n",
    "print(f\"Recall@5: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b316d1",
   "metadata": {},
   "source": [
    "# Session-based RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9978fb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0423\n",
      "Epoch 2/10, Loss: 0.0061\n",
      "Epoch 3/10, Loss: 0.0011\n",
      "Epoch 4/10, Loss: 0.0005\n",
      "Epoch 5/10, Loss: 0.0003\n",
      "Epoch 6/10, Loss: 0.0002\n",
      "Epoch 7/10, Loss: 0.0001\n",
      "Epoch 8/10, Loss: 0.0001\n",
      "Epoch 9/10, Loss: 0.0001\n",
      "Epoch 10/10, Loss: 0.0001\n",
      "Test Accuracy: 1.0000\n",
      "Sample user sequence: [28 29 30 31 32]\n",
      "Top 5 recommendations: [33 34 32 19 38]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming you've already run the data simulation code you provided\n",
    "\n",
    "# Preprocess the data\n",
    "le_user = LabelEncoder()\n",
    "le_item = LabelEncoder()\n",
    "\n",
    "df['user_id'] = le_user.fit_transform(df['user_id'])\n",
    "df['item_id'] = le_item.fit_transform(df['item_id'])\n",
    "\n",
    "# Create sequences for each user\n",
    "def create_sequences(user_df, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for _, group in user_df.groupby('user_id'):\n",
    "        item_ids = group['item_id'].tolist()\n",
    "        for i in range(len(item_ids) - seq_length):\n",
    "            seq = item_ids[i:i+seq_length]\n",
    "            label = item_ids[i+seq_length]\n",
    "            sequences.append(seq)\n",
    "            labels.append(label)\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "seq_length = 5\n",
    "sequences, labels = create_sequences(df, seq_length)\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.LongTensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "X_test = torch.LongTensor(X_test)\n",
    "y_test = torch.LongTensor(y_test)\n",
    "\n",
    "# Define the RNN model\n",
    "class SessionRNN(nn.Module):\n",
    "    def __init__(self, n_items, embedding_dim, hidden_dim):\n",
    "        super(SessionRNN, self).__init__()\n",
    "        self.item_embeddings = nn.Embedding(n_items, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, n_items)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedded = self.item_embeddings(x)\n",
    "        output, _ = self.gru(embedded)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return output\n",
    "\n",
    "# Set hyperparameters\n",
    "n_items = len(le_item.classes_)\n",
    "embedding_dim = 50\n",
    "hidden_dim = 100\n",
    "batch_size = 64\n",
    "n_epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = SessionRNN(n_items, embedding_dim, hidden_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(X_train), batch_size):\n",
    "        batch_X = X_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {total_loss/len(X_train):.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_test)\n",
    "    _, predicted = torch.max(test_outputs, 1)\n",
    "    accuracy = (predicted == y_test).float().mean()\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Function to get recommendations\n",
    "def get_recommendations(model, user_sequence, n_recommendations=5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = torch.LongTensor(user_sequence).unsqueeze(0)\n",
    "        output = model(sequence)\n",
    "        _, top_items = torch.topk(output, n_recommendations)\n",
    "        return le_item.inverse_transform(top_items.squeeze().numpy())\n",
    "\n",
    "# Example: Get recommendations for a sample user sequence\n",
    "sample_sequence = X_test[0].numpy()\n",
    "recommendations = get_recommendations(model, sample_sequence)\n",
    "print(f\"Sample user sequence: {le_item.inverse_transform(sample_sequence)}\")\n",
    "print(f\"Top 5 recommendations: {recommendations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157da5d7",
   "metadata": {},
   "source": [
    "# Attention mechanisms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ab889f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.9239\n",
      "Epoch 2/10, Loss: 0.9231\n",
      "Epoch 3/10, Loss: 0.9228\n",
      "Epoch 4/10, Loss: 0.9226\n",
      "Epoch 5/10, Loss: 0.9223\n",
      "Epoch 6/10, Loss: 0.9221\n",
      "Epoch 7/10, Loss: 0.9220\n",
      "Epoch 8/10, Loss: 0.9219\n",
      "Epoch 9/10, Loss: 0.9217\n",
      "Epoch 10/10, Loss: 0.9216\n",
      "Test Accuracy: 0.4987\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assume train_df and test_df are already loaded\n",
    "\n",
    "# Prepare data for PyTorch\n",
    "def prepare_data(df):\n",
    "    user_features = df[[col for col in df.columns if col.startswith('userfeature')]].values\n",
    "    item_features = df[[col for col in df.columns if col.startswith('itemfeature')]].values\n",
    "    interactions = df['interaction'].values\n",
    "    return torch.FloatTensor(user_features), torch.FloatTensor(item_features), torch.FloatTensor(interactions)\n",
    "\n",
    "X_user_train, X_item_train, y_train = prepare_data(train_df)\n",
    "X_user_test, X_item_test, y_test = prepare_data(test_df)\n",
    "\n",
    "# Define the attention-based model\n",
    "class AttentionRecommender(nn.Module):\n",
    "    def __init__(self, n_features, hidden_dim):\n",
    "        super(AttentionRecommender, self).__init__()\n",
    "        self.user_embedding = nn.Linear(n_features, hidden_dim)\n",
    "        self.item_embedding = nn.Linear(n_features, hidden_dim)\n",
    "        self.attention = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, user_features, item_features):\n",
    "        user_embedded = self.user_embedding(user_features)\n",
    "        item_embedded = self.item_embedding(item_features)\n",
    "        concat = torch.cat((user_embedded, item_embedded), dim=1)\n",
    "        attention_weights = self.attention(concat)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)\n",
    "        weighted_features = attention_weights * concat\n",
    "        output = self.fc(weighted_features)\n",
    "        return self.sigmoid(output)\n",
    "\n",
    "# Set hyperparameters\n",
    "n_features = X_user_train.shape[1]\n",
    "hidden_dim = 64\n",
    "n_epochs = 10\n",
    "batch_size = 1024\n",
    "lr = 0.001\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = AttentionRecommender(n_features, hidden_dim)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for i in range(0, len(X_user_train), batch_size):\n",
    "        batch_user = X_user_train[i:i+batch_size]\n",
    "        batch_item = X_item_train[i:i+batch_size]\n",
    "        batch_y = y_train[i:i+batch_size]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_user, batch_item).squeeze()\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / (len(X_user_train) // batch_size)\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = model(X_user_test, X_item_test).squeeze()\n",
    "    predictions = (test_outputs > 0.5).float()\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5eba8b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323dd700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97359eeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
